{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from keras.layers import Dense, Flatten, Reshape, Conv2DTranspose, Conv2D, BatchNormalization, LeakyReLU, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_dim = (112, 168)\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "image_directory = 'data/processed_images_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Data recuperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory)]\n",
    "\n",
    "image_list = []\n",
    "for image_path in image_paths:\n",
    "    with Image.open(image_path) as img:\n",
    "        pixel_values = np.array(img.resize(resized_dim))\n",
    "\n",
    "    image_list.append(pixel_values)\n",
    "\n",
    "image_np_array = np.array(image_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(image_np_array).shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print first image of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_dataset.take(1))\n",
    "\n",
    "first_image = next(iterator)\n",
    "\n",
    "plt.imshow(first_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (168, 112, 3)\n",
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Commencez par une couche Dense qui prend l'input de la dimension de l'espace latent z\n",
    "    # La première couche Dense est un pré-traitement pour obtenir la forme désirée\n",
    "    model.add(Dense(21*14*256, use_bias=False, input_shape=(z_dim,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    # Redimensionnement pour passer à la forme 21x14x256\n",
    "    model.add(Reshape((21, 14, 256)))\n",
    "\n",
    "    # Upsampling à 42x28\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 42, 28, 128)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    # Upsampling à 84x56\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 84, 56, 64)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    # Dernier upsampling pour obtenir 168x112\n",
    "    model.add(Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 168, 112, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(z_dim)\n",
    "\n",
    "noise = tf.random.normal([1, z_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Couche d'entrée\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Couche intermédiaire\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Couche de sortie\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator(image_shape)\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définissez la dimension de l'espace latent z\n",
    "z_dim = 100\n",
    "\n",
    "# Créez le générateur et le discriminateur avec les nouvelles formes\n",
    "generator = build_generator(z_dim)\n",
    "discriminator = build_discriminator((168, 112, 3))\n",
    "\n",
    "# Compilez le discriminateur\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Créez le modèle GAN complet\n",
    "discriminator.trainable = False  # Très important pour s'assurer que le discriminateur n'est pas entraîné lors de l'entraînement du générateur via le modèle GAN\n",
    "gan_input = tf.keras.Input(shape=(z_dim,))\n",
    "fake_image = generator(gan_input)\n",
    "gan_output = discriminator(fake_image)\n",
    "\n",
    "# Compilez le modèle GAN complet\n",
    "gan = tf.keras.Model(gan_input, gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(generator, z_dim, epoch):\n",
    "    noise = tf.random.normal([1, z_dim])\n",
    "    generated_images = generator(noise, training=False)\n",
    "    generated_images = (generated_images + 1) / 2 \n",
    "\n",
    "    plt.imshow(generated_images)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, dataset, z_dim, epochs=100, batch_size=32, save_interval=5):\n",
    "    size_of_dataset = sum(1 for _ in dataset)\n",
    "    steps_per_epoch = size_of_dataset // batch_size\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for _, real_images in enumerate(dataset.take(steps_per_epoch)):\n",
    "            noise = tf.random.normal([batch_size, z_dim])\n",
    "\n",
    "            with tf.GradientTape() as disc_tape:\n",
    "                fake_images = generator(noise, training=False)\n",
    "                real_output = discriminator(real_images, training=True)\n",
    "                fake_output = discriminator(fake_images, training=True)\n",
    "\n",
    "                disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "            gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "            noise = tf.random.normal([batch_size, z_dim])\n",
    "\n",
    "            with tf.GradientTape() as gen_tape:\n",
    "                fake_images = generator(noise, training=True)\n",
    "                fake_output = discriminator(fake_images, training=False)\n",
    "                gen_loss = generator_loss(fake_output)\n",
    "\n",
    "            gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "        print(f'Époque {epoch}/{epochs}, Discriminator Loss: {disc_loss.numpy()}, Generator Loss: {gen_loss.numpy()}')\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            display_sample_images(generator, z_dim, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(generator, discriminator, gan, train_dataset, z_dim, epochs=10000, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, z_dim])\n",
    "\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "generated_image = (generated_image.numpy().squeeze() * 127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "plt.imshow(generated_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cards_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
